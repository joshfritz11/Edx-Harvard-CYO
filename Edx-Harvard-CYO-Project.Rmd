---
title: 'Understanding the Benefits and Limitations of the *Caret* Package using the UCI Dry Bean Dataset'
author: "Josh Fritz"
date: "2023-03-05"
always_allow_html: true
output:
  html_document: default
  word_document: default
  pdf_document:
    latex_engine: pdflatex
bibliography: references.bib
biblio-style: apalike
link-citations: yes
colorlinks: yes
urlcolor: blue
graphics: yes
header-includes:
- \usepackage{caption}
- \captionsetup[figure]{labelformat=empty}
- \usepackage{arev}
- \usepackage[T1]{fontenc}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
- \usepackage{fvextra}
- \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy.ops=list(width.cutoff=60), tidy=TRUE)
```

## Introduction
The R programming language has several packages implementing machine learning. For linear regression alone, there are *logicFS*, *lars*, and *monomvn* to name a few [@kuhn]. Consequentially each package has different functions for training models and making predictions. To simplify these differences, the *caret* package has standardized training and predicting functions. Although *caret* standardizes machine learning functions, this simplification also prevents users from specifying parameters present in the algorithm's original package. For example, for training a multi-layer perceptron (MLP) model, the *caret* package has one tuning parameter `size` for specifying the number of units in the hidden layer. To contrast, the same algorithm initialized from the *RSNNS* package has several tuning parameters [@mlp]. The goal of this project was to better understand the benefits and limitations of the *caret* package using the UCI Dry Bean Dataset.

The Dry Bean Dataset was developed by Koklu and Ozkan at Selcuk University in Turkey [@koklu2020multiclass]. This dataset was chosen because it has over ten-thousand entries and Koklu and Ozkan implemented four machine learning algorithms for classifying the beans. The algorthims were: multi-layer perceptron (MLP), support vector machine (SVM), k-nearest neighbors (kNN), and decision tree (DT). Because there are published results for different algorithms on this dataset, this project's aim was to implement similar algorithms using the *caret* package and compare the results with the Koklu and Ozkan results.

#### *Dry Bean Dataset Description*
```{r Dry Bean Data Download, message=FALSE, warning=FALSE, include=FALSE}
if (!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if (!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)

# Dry Bean Dataset
# https://archive-beta.ics.uci.edu/dataset/602/dry+bean+dataset
# https://archive.ics.uci.edu/ml/machine-learning-databases/00602/DryBeanDataset.zip

options(timeout = 120)

dl <- "DryBeanDataset.zip"
if (!file.exists(dl))
    download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/00602/DryBeanDataset.zip", dl)

Dry_Bean_Dataset_file <- "DryBeanDataset/Dry_Bean_Dataset.xlsx"
if (!file.exists(Dry_Bean_Dataset_file))
    unzip(dl, Dry_Bean_Dataset_file)

Dry_Bean_Dataset <- readxl::read_xlsx(Dry_Bean_Dataset_file,
          col_names = TRUE,
          trim_ws = TRUE)

# Test set will be 10% of the data.
set.seed(1, sample.kind = "Rounding") # if using R 3.6 or later
test_index <- createDataPartition(y = Dry_Bean_Dataset$Class, times = 1, p = 0.1, list = FALSE)
train_set <- Dry_Bean_Dataset[-test_index, ]
test_set <- Dry_Bean_Dataset[test_index, ]
```
The Dry Bean Dataset contains 13,611 entries and classifies the entries into one of seven different dry bean types. The seven dry bean types are: barbunya, bombay, cali, dermason, horoz, seker, and sira. Table 1 shows the observation count for the different types.

```{r Table 1: First five rows of MovieLens data table, message=FALSE, warning=FALSE, echo=FALSE}
if (!require(kableExtra)) install.packages("kableExtra")

library(kableExtra)

Bean_Type_Count <- Dry_Bean_Dataset %>%
    group_by(.$Class) %>%
    summarize(n())

kable_styling(kbl(Bean_Type_Count, booktabs = T, col.names = c("Bean Type", "Count")),
              latex_options = c("striped", "scale_down", "hold_position")) |>
  footnote(general = "Table 1: Count of bean types", general_title = "")
```

In addition to classifications, it has information about each dry bean's entry in the following variables:

* Area (A): The area of the bean zone and the number of pixels within its boundaries.
* Perimeter (P): Length of the bean's border.
* Major axis length (L): The distance of the longest line that can be drawn from a bean.
* Minor axis length (l): The longest line that can be drawn that is perpendicular to the main axis.
* Aspect ratio (k): The relationship between L and I as $K = \frac{L}{l}$.
* Eccentricity (Ec): Eccentricity of the ellipse having the same moments as the region.
* Convex area (C): Number of pixels in the smallest convex polygon that can contain the area of a bean seed.
* Equivalent diameter (Ed): The diameter of a circle having the same area as a bean seed area. Written as $d = \sqrt{\frac{4 * A}{\pi}}$.
* Extent (Ex): The ratio of the pixels in the bounding box to the bean area. Written as $Ex = \frac{A}{A_B}$ where $A_B$ is the area of the bounding rectangle.
* Solidity (S): The ratio of the pixels in the convex shell to those found in beans. Written as $S = \frac{A}{C}$.
* Roundness (R): Calculated using $R = \frac{4 \pi A}{p^2}$.
* Compactness(CO): Measures the roundness of an object as $CO = \frac{Ed}{L}$.
* Shape Factor 1 (SF1): Calculated as $SF1 = \frac{L}{A}$.
* Shape Factor 2 (SF2): Calculated as $SF2 = \frac{l}{A}$.
* Shape Factor 3 (SF3): Calculated as $SF3 = \frac{A}{\frac{L}{2} * \frac{L}{2} * \pi}$.
* Shape Factor 4 (SF4): Calculated as $SF4 = \frac{A}{\frac{l}{2} * \frac{l}{2} * \pi}$.

## Methods and Analysis - explains the process and techniques used, including data cleaning, data exploration and visualization, any insights gained, and your modeling approach. At least two different models or algorithms must be used, with at least one being more advanced than linear or logistic regression for prediction problems.
#### *Data Visualization*
Before training models and using them to make predictions, box plots for each variable were made to understand how the bean types differ from each other. From the box plots, it is apparent the Bombay type is distinct from the others with variables like area, perimeter, major axis length, minor axis length, convex area, and equivalent diameter. To contrast, the other bean types had regions of feature overlap with at least one other type, meaning it is difficult to differentiate them with descriptive statistics alone. Figure 1 shows example box plots for variables where Bombay beans are distinct and not distinct from the other types. Also note how other bean types are difficult to classify with these variables.
```{r Figure 1, message=FALSE, warning=FALSE, echo=FALSE, fig.show="hold", fig.alt="Figure 1: Box plots showing where Bombay beans are distinct and where they are not", fig.cap="Figure 1: Box plots showing where Bombay beans are distinct and where they are not"}
if (!require(gridExtra)) install.packages("gridExtra")
library(gridExtra)

AXIS_TEXT_X_ANGLE <- 45
AXIS_TEXT_VJUST <- 0.5

BoxPlot_Area <- Dry_Bean_Dataset |> ggplot(aes(Class, Area)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Area")

BoxPlot_Perimeter <- Dry_Bean_Dataset |> ggplot(aes(Class, Perimeter)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Perimeter")

BoxPlot_MajorAxisLength <- Dry_Bean_Dataset |> ggplot(aes(Class, MajorAxisLength)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Major Axis Length")

BoxPlot_MinorAxisLength <- Dry_Bean_Dataset |> ggplot(aes(Class, MinorAxisLength)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Minor Axis Length")

BoxPlot_AspectRatio <- Dry_Bean_Dataset |> ggplot(aes(Class, AspectRation)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Aspect Ratio")

BoxPlot_Eccentricity <- Dry_Bean_Dataset |> ggplot(aes(Class, Eccentricity)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Eccentricity")

BoxPlot_ConvexArea <- Dry_Bean_Dataset |> ggplot(aes(Class, ConvexArea)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Convex Area")

BoxPlot_EquivaDiameter <- Dry_Bean_Dataset |> ggplot(aes(Class, EquivDiameter)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Equivalent Diameter")

BoxPlot_Extent <- Dry_Bean_Dataset |> ggplot(aes(Class, Extent)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Extent")

BoxPlot_Solidity <- Dry_Bean_Dataset |> ggplot(aes(Class, Solidity)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Solidity")

BoxPlot_Roundness <- Dry_Bean_Dataset |> ggplot(aes(Class, roundness)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Roundness")

BoxPlot_Compactness <- Dry_Bean_Dataset |> ggplot(aes(Class, Compactness)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Compactness")

BoxPlot_ShapeFactor1 <- Dry_Bean_Dataset |> ggplot(aes(Class, ShapeFactor1)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Shape Factor 1")

BoxPlot_ShapeFactor2 <- Dry_Bean_Dataset |> ggplot(aes(Class, ShapeFactor2)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Shape Factor 2")

BoxPlot_ShapeFactor3 <- Dry_Bean_Dataset |> ggplot(aes(Class, ShapeFactor3)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Shape Factor 3")

BoxPlot_ShapeFactor4 <- Dry_Bean_Dataset |> ggplot(aes(Class, ShapeFactor4)) +
    geom_boxplot() +
    theme_light() + 
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.text.x = element_text(angle = AXIS_TEXT_X_ANGLE, vjust = AXIS_TEXT_VJUST),
          panel.grid.minor.y = element_blank()) +
    labs(x = "", y = "Shape Factor 4")

# Commented out this code because the output does not look good. However, can be uncommented for viewing as needed.
# Grob_Layout <- rbind(c(1, 2, 3, 4),
#                      c(5, 6, 7, 8),
#                      c(9, 10, 11, 12),
#                      c(13, 14, 15, 16))

# Grob_Plots <- arrangeGrob(grobs = list(BoxPlot_Area, BoxPlot_Perimeter, BoxPlot_MajorAxisLength, BoxPlot_MinorAxisLength,
#                                        BoxPlot_AspectRatio, BoxPlot_Eccentricity, BoxPlot_ConvexArea, BoxPlot_EquivaDiameter,
#                                        BoxPlot_Extent, BoxPlot_Solidity, BoxPlot_Roundness, BoxPlot_Compactness,
#                                        BoxPlot_ShapeFactor1, BoxPlot_ShapeFactor2, BoxPlot_ShapeFactor3, BoxPlot_ShapeFactor4), layout_matrix = Grob_Layout)

Grob_Layout <- rbind(c(1, 2),
                     c(3, 4))

Grob_Plots <- arrangeGrob(grobs = list(BoxPlot_Area, BoxPlot_Perimeter,
                                       BoxPlot_Extent, BoxPlot_Solidity), layout_matrix = Grob_Layout)
grid.arrange(Grob_Plots)
```
#### *Data Partitioning*
For training and testing models, the Dry Bean Dataset was partitioned into training and test sets using *caret's* `createDataPartition` function. The partition was made with 90% of the data going to the training set while 10% went to the test set. These proportions were chosen because they are similar to the ones used in Koklu and Ozkan study [@koklu2020multiclass]. However, in their study, they used 10-fold cross-validation instead of partitioning separate training and test sets. This means for every iteration in cross-validation used 90% of the data for training and 10% for testing.
```{r Dry Bean Training and Test Set Partitioning, message=FALSE, warning=FALSE, include=FALSE}
# Test set will be 10% of the data.
set.seed(1, sample.kind = "Rounding") # if using R 3.6 or later
test_index <- createDataPartition(y = Dry_Bean_Dataset$Class, times = 1, p = 0.1, list = FALSE)
train_set <- Dry_Bean_Dataset[-test_index, ]
test_set <- Dry_Bean_Dataset[test_index, ]
```

#### *Control Models*
The first models created were control models to understand the accuracy of guessing bean types. The models were a random guessing model and a proportional guessing model. The random guessing model randomly assigns a bean type for every row in the test set using R's `sample` function. Although random guesses produce a worst-case model, they do not reflect the proportion of bean types in the training set as shown in figure 2. Therefore the proportional model was made using the training set to reflect its bean type proportions. The proportion model was also made with the `sample` by setting its `prob` parameter to the training set's proportion of bean types. Figure 3 shows how the proportion model's output compares to the proportion of the training set's bean types.
```{r Control Models, message=FALSE, warning=FALSE, include=FALSE}
# Random guessing model
bean_classes <- unique(train_set$Class)
test_set_length <- length(test_set$Class)

y_hat_random <- tibble(Class = sample(bean_classes, test_set_length, replace = TRUE))

# Proportional guessing model
bean_proportions <- map_df(bean_classes, function(bean_class){
    list(Class = bean_class,
         Proportion = mean(train_set$Class == bean_class))
})

y_hat_proportion <- tibble(Class = sample(bean_classes, test_set_length, replace = TRUE, prob = bean_proportions$Proportion))
```

```{r Figure 2, message=FALSE, warning=FALSE, echo=FALSE, fig.align="center", fig.show="hold", out.width="49%", out.height="49%", fig.alt="Figure 2: Comparing distributions between random guessing model and training set. The distributions are not similar.", fig.cap="Figure 2: Comparing distributions between random guessing model and training set. The distributions are not similar."}
CAPTION_FONT_SIZE <- 12

y_hat_random |> ggplot(aes(Class)) + 
  geom_bar(color = "black") +
  theme_light() + 
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        plot.caption = element_text(hjust = 0, size = CAPTION_FONT_SIZE)) + 
  labs(x = "", y = "Count",
       caption = "a: Random prediction bean types have uniform distribution")

train_set |> ggplot(aes(Class)) + 
  geom_bar(color = "black") +
  theme_light() + 
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        plot.caption = element_text(hjust = 0, size = CAPTION_FONT_SIZE)) + 
  labs(x = "", y = "Count",
       caption = "b: Training set bean types do not have a uniform distribution")
```
```{r Figure 3, message=FALSE, warning=FALSE, echo=FALSE, fig.align="center", fig.show="hold", out.width="49%", out.height="49%", fig.alt="Figure 3: Comparing distributions between proportional guessing model and train set. The distributions are similar.", fig.cap="Figure 3: Comparing distributions between proportional guessing model and train set. The distributions are similar."}
y_hat_proportion |> ggplot(aes(Class)) + 
  geom_bar(color = "black") +
  theme_light() + 
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        plot.caption = element_text(hjust = 0, size = CAPTION_FONT_SIZE)) + 
  labs(x = "", y = "Count",
       caption = "a: Proportional guessing model")

train_set |> ggplot(aes(Class)) + 
  geom_bar(color = "black") +
  theme_light() + 
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        plot.caption = element_text(hjust = 0, size = CAPTION_FONT_SIZE)) + 
  labs(x = "", y = "Count",
       caption = "b: Training set bean types")
```
#### *Multi-layer Perceptron Model*
The first machine learning model created was a multi-layer perceptron model. This model is an artificial neural network that is robust to training errors and can be applied to discrete-valued problems [@mitchellmachine]. It takes inspiration from biology through systems of interconnected neurons. Instead of neurons, it creates an interconnected set of simple units that each take several inputs and produce a single output.

Training the multi-layer perceptron model was done using the *caret* package's `train` function using the training set. The function was set to learn the class using all the dry bean's variables. The method used was "mlp" from the *RSNNS* package [@mlp]. To improve the model's performance, 10-fold cross-validation was used similar to the Koklu and Ozkan study. Although cross-validation was used there were several parameters that differed from Koklu and Ozkan's study. For example, Koklu and Ozkan specified a hidden layer number of two, while the *caret* model was allowed to set its hidden layer number based on the results of the train function. To do this, the model's `size` parameter was set to try hidden layer numbers from one to five. These numbers were chosen based on the results of the final model. For example, if the final model had a size of five, then the range of sizes would have been increased until a size within the range was selected. Additionally, Koklu and Ozkan's study specified other parameters like hidden layer activation function, learning rate, and performance goal. The *caret* model did not have options for setting these parameters, but the function does set these parameters when it is executed. Further discussion of these parameters is discussed in the results section.

After training the first multi-layer perceptron model, the model's accuracy was lower than expected. To increase the model's accuracy, a second model was made using the *caret* `preProcess` parameter. This parameter was set to center and scale the data before it was used to make predictions. The results of this model are discussed in the results section.
```{r Multi-layer Perceptron Models, message=FALSE, warning=FALSE, include=FALSE}
if (!require(RSNNS)) install.packages("RSNNS")

# MLP without pre-processing
control <- trainControl(method = "cv", number = 10)

train_mlp <- train(Class ~ .,
                   data = train_set,
                   method = "mlp",
                   tuneGrid = data.frame(size = seq(1, 5, 1)),
                   trControl = control)

y_hat_mlp <- predict(train_mlp, test_set)

# MLP with pre-processing
train_mlp_preprocessing <- train(Class ~ .,
                                 data = train_set,
                                 method = "mlp",
                                 tuneGrid = data.frame(size = seq(1, 11, 2)),
                                 trControl = control,
                                 preProcess = c("center", "scale"))

y_hat_mlp_preprocessing <- predict(train_mlp_preprocessing, test_set)
```


#### *Support Vector Machine Model*
The second model was made with a support vector machine. Building this model was done similar to the multi-layer perceptron model using the *caret* `train` function on the training data with 10-fold cross-validation. Unlike the multi-layer perceptron model, the method used was "svmLinear" from the *kernlab* package [@svm]. Furthermore, the tuning parameter specified was cost, which was set to try values from 10 to 20. Specifying this parameter differed from the Koklu and Ozkan study because they did not specify cost. Instead they specified what type of generalization to use, which was on-vs.-one.
```{r Support Vector Machine Model, message=FALSE, warning=FALSE, include=FALSE}
control <- trainControl(method = "cv", number = 10)

train_svm <- train(Class ~ .,
                   data = train_set,
                   method = "svmLinear",
                   tuneGrid = data.frame(C = seq(10, 20, 2)),
                   trControl = control)

y_hat_svm <- predict(train_svm, test_set)
```


#### *k-Nearest Neighbors Model*
The third model was made using k-nearest neighbors. This method uses instance-based learning, which stores the training examples in memory without generalizing beyond them [@mitchellmachine]. Generalization occurs when a new instance must be classified. Building this model was similar to the other *caret* models. The method used was "knn" from the *caret* package [@kuhn]. In this case, the tuning parameter was the number of neighbors, which was set to try values between one and five. In the Koklu and Ozkan study, the number of neighbors specified was 10.
```{r k-Nearest Neighbors Model, message=FALSE, warning=FALSE, include=FALSE}
control <- trainControl(method = "cv", number = 10)

train_knn <- train(Class ~ .,
                   data = train_set,
                   method = "knn",
                   tuneGrid = data.frame(k = seq(1, 5, 2)),
                   trControl = control)

y_hat_knn <- predict(train_knn, test_set)
```


#### *Random Forest Model*
The fourth model made is also the last model to compare with the Koklu and Ozkan study. The Koklu and Ozkan study used a decision tree model, but for this study the *caret* model chosen was a random forest from the *randomForest* package [@randomForest]. Random forest was used because it improves predictions by averaging multiple decision trees [irizarry2022]. For the random forest model, several tuning parameters were specified. First, the number of variables randomly sampled was 1, 5, 10, 25, 50, and 100. Next the number of trees was set to 150. Finally, the size of samples to draw was 5000. To contrast from this study's model, the Koklu and Ozkan study's decision tree model specified a maximum number of partitions as 16. This parameter was not specified in the random forest model.
```{r Random Forest Model, message=FALSE, warning=FALSE, include=FALSE}
if (!require(randomForest)) install.packages("randomForest")

control <- trainControl(method = "cv", number = 10)
grid <- data.frame(mtry = c(1, 5, 10, 25, 50, 100))

train_rf <- train(Class ~ .,
                  data = train_set,
                  method = "rf",
                  ntree = 150,
                  trControl = control,
                  tuneGrid = grid,
                  nsamp = 5000)

y_hat_rf <- predict(train_rf, test_set)
```


#### *Naive Bayes Classifier Model*
TODO: Create the models from the Koklu and Ozkan paper. Reference the Machine Learning textbook where possible.
TODO: Describe the differences in implementing the Caret model versus the Koklu and Ozkan models.

The final model made was a naive Bayes classifier.

```{r Naive Bayes Classifier Model, message=FALSE, warning=FALSE, include=FALSE}
if (!require(naivebayes)) install.packages("naivebayes")

control <- trainControl(method = "cv", number = 10)

train_naive_bayes_classifier <- train(Class ~ .,
                                      data = train_set,
                                      method = "naive_bayes",
                                      trControl = control)

y_hat_naive_bayes_classifier <- predict(train_naive_bayes_classifier, test_set)
```


## Results - presents the modeling results and discusses the model performance.
TODO: Display each model's accuracy.
TODO: Discuss how the model accuracies differed between the Koklu and Ozkan and my models.

## Conclusion - gives a brief summary of the report, its potential impact, its limitations, and future work.


## References {.unnumbered}